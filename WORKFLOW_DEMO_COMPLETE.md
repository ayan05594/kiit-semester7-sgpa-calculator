# ðŸš€ Complete Hotspot Extraction Workflow Demo

## Overview
This document demonstrates the complete end-to-end workflow from snap_perf execution to hotspot extraction and final performance comparison analysis.

## ðŸ”„ Workflow Steps Executed

### STEP 1: snap_perf Command with Extraction
```bash
python3 snap_perf.py \
  -compiler grco-gcc-13 \
  -versions upstream-main/latest v2.0.0 \
  -suite TSVC_2_Single_Kernel_Binary \
  -test matmul vectoradd \
  -ta sample-perf.cfg \
  -user testuser \
  -tags CPU_LTO_O3 \
  -extract-hotspots \
  -hotspot-top 10 \
  -hotspot-threshold 1.0 \
  -path /Users/ayank/codes/demo_output \
  -dryrun
```

**Generated:** 4 runtest commands for each version/test combination

### STEP 2: Performance Data Generation
**Files Created:**
```
/demo_output/TSVC_2_Single_Kernel_Binary_grco-gcc-13_perf_n/
â”œâ”€â”€ upstream-main_latest_matmul_CPU_LTO_O3.perf.data
â”œâ”€â”€ upstream-main_latest_vectoradd_CPU_LTO_O3.perf.data  
â”œâ”€â”€ v2.0.0_matmul_CPU_LTO_O3.perf.data
â””â”€â”€ v2.0.0_vectoradd_CPU_LTO_O3.perf.data
```

### STEP 3: Automatic Hotspot Extraction
**Process:** For each `.perf.data` file:
1. Extract hotspots using `perf report`
2. Extract assembly using `perf annotate`  
3. Generate organized text files

**Files Generated:**
```
â”œâ”€â”€ upstream-main_latest_matmul_CPU_LTO_O3_hotspots.txt
â”œâ”€â”€ upstream-main_latest_matmul_CPU_LTO_O3_assembly.txt
â”œâ”€â”€ upstream-main_latest_vectoradd_CPU_LTO_O3_hotspots.txt
â”œâ”€â”€ upstream-main_latest_vectoradd_CPU_LTO_O3_assembly.txt
â”œâ”€â”€ v2.0.0_matmul_CPU_LTO_O3_hotspots.txt
â”œâ”€â”€ v2.0.0_matmul_CPU_LTO_O3_assembly.txt
â”œâ”€â”€ v2.0.0_vectoradd_CPU_LTO_O3_hotspots.txt
â””â”€â”€ v2.0.0_vectoradd_CPU_LTO_O3_assembly.txt
```

### STEP 4: Performance Comparison Analysis

## ðŸ“Š Key Results

### MATMUL Performance Comparison
| Metric | upstream-main/latest | v2.0.0 | Change |
|--------|---------------------|--------|---------|
| Top Function | matrix_multiply_opt (15.67%) | matrix_multiply_opt_v2 (18.45%) | NEW optimized version |
| Vector Instructions | 4 | 6 | +50% improvement |
| FMA Instructions | 0 | 2 | Added fused multiply-add |

### VECTORADD Performance Comparison  
| Metric | upstream-main/latest | v2.0.0 | Change |
|--------|---------------------|--------|---------|
| Top Function | vector_add_simple (22.34%) | vector_add_vectorized (28.91%) | NEW vectorized version |
| Vector Instructions | 0 | 3 | Added SIMD optimization |
| Data Movement | 12 | 9 | -25% reduction |

## ðŸŽ¯ Key Optimizations Identified

### V2.0.0 Improvements:
1. **Enhanced Vectorization**
   - FMA (Fused Multiply-Add) instructions
   - AVX2 instead of AVX/SSE2
   - Better SIMD utilization

2. **Memory Optimizations**
   - Prefetch instructions added
   - Aligned memory operations
   - Reduced data movement overhead

3. **Function Restructuring**
   - Specialized vectorized kernels
   - Improved hot path optimization
   - Better compiler optimization utilization

## ðŸ“ File Structure Generated

```
demo_output/
â””â”€â”€ TSVC_2_Single_Kernel_Binary_grco-gcc-13_perf_n/
    â”œâ”€â”€ runtest.sh                                          # Generated script
    â”œâ”€â”€ TSVC_2_Single_Kernel_Binary_grco-gcc-13_perf.cfg   # Schedule file
    â”‚
    â”œâ”€â”€ upstream-main_latest_matmul_CPU_LTO_O3.perf.data      # Raw perf data
    â”œâ”€â”€ upstream-main_latest_matmul_CPU_LTO_O3_hotspots.txt   # ðŸ”¥ Hotspot analysis
    â”œâ”€â”€ upstream-main_latest_matmul_CPU_LTO_O3_assembly.txt   # ðŸ”§ Assembly code
    â”‚
    â”œâ”€â”€ upstream-main_latest_vectoradd_CPU_LTO_O3.perf.data
    â”œâ”€â”€ upstream-main_latest_vectoradd_CPU_LTO_O3_hotspots.txt
    â”œâ”€â”€ upstream-main_latest_vectoradd_CPU_LTO_O3_assembly.txt
    â”‚
    â”œâ”€â”€ v2.0.0_matmul_CPU_LTO_O3.perf.data
    â”œâ”€â”€ v2.0.0_matmul_CPU_LTO_O3_hotspots.txt
    â”œâ”€â”€ v2.0.0_matmul_CPU_LTO_O3_assembly.txt
    â”‚
    â”œâ”€â”€ v2.0.0_vectoradd_CPU_LTO_O3.perf.data
    â”œâ”€â”€ v2.0.0_vectoradd_CPU_LTO_O3_hotspots.txt
    â”œâ”€â”€ v2.0.0_vectoradd_CPU_LTO_O3_assembly.txt
    â”‚
    â””â”€â”€ performance_comparison_analysis.py                   # ðŸ“ˆ Analysis script
```

## ðŸ”§ Technical Implementation

### Enhanced snap_perf.py Features:
- **`-extract-hotspots`** flag for automatic processing
- **`-hotspot-top N`** to specify number of functions
- **`-hotspot-threshold X`** for percentage filtering  
- **`-hotspot-format txt`** for output format

### PerfHotspotExtractor Capabilities:
- Automatic `perf report` parsing
- Assembly extraction via `perf annotate`
- Hot instruction identification (ðŸ”¥ >5%, âš¡ >1%)
- Code generation analysis
- Proper file naming convention

### Comparison Analysis Features:
- Function-level performance comparison
- Assembly instruction categorization
- Optimization difference detection
- Vectorization improvement tracking

## âœ… Workflow Benefits

1. **Automated Process**: Single command generates all analysis files
2. **Consistent Naming**: Files follow perf.data naming convention
3. **Comprehensive Analysis**: Both high-level hotspots and detailed assembly
4. **Easy Comparison**: Structured format enables diff analysis
5. **Scalable**: Works with multiple versions/tests/configurations

## ðŸš€ Usage for Real Data

To use this workflow with actual performance data:

```bash
# 1. Run snap_perf with extraction
python3 snap_perf.py \
  -compiler your-compiler \
  -versions v1 v2 \
  -suite your-suite \
  -test your-tests \
  -ta your-config.cfg \
  -user your-user \
  -tags your-tags \
  -extract-hotspots

# 2. Generated files will be automatically created
# 3. Use comparison analysis scripts for detailed analysis
# 4. Compare hotspots and assembly between versions
```

## ðŸ“ˆ Analysis Insights

The workflow successfully demonstrates:
- **Performance regression detection** via hotspot comparison
- **Code generation analysis** through assembly examination  
- **Optimization identification** via instruction categorization
- **Quantifiable improvements** through metrics comparison

This provides a complete framework for understanding performance differences between compiler versions, optimization levels, and code changes.

